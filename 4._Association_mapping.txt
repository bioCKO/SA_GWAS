install.packages("ggplot2")
library(ggplot2)
install.packages("GenABEL")
library(GenABEL)
install.packages("qqman")
library(qqman)
install.packages("scales")
library(scales)
install.packages("data.table")
library(data.table)

dir <- "~/Desktop/PloS_Biol_revision/"

## Note that original folders are sometimes retained because paste0(dir,"filename") nomenclature was adopted later for readability

###################################################
## SNP heritability of the antagonism index
###################################################

----- R code -----

## Make 1000 permuted phenotypes
## Import individuals retained for GWAS
good.indv <- read.table(paste0(dir,"f3c.lhm.snp.fam"))
good.indv <- good.indv[,1]

## Create a thousand 'pheno.txt' files where individual labels have been shuffled (but other columns are otherwise unchanged)
set.seed(123)
for (i in 1:1000){
  #Original folder was '~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/'
  pheno <- read.table("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/pheno.txt",head=T)
  pheno <- subset(pheno,IID %in% good.indv)
  newcols <- sample(pheno[,1],replace=F,size=nrow(pheno))
  pheno$IID <- newcols
  pheno$FID <- newcols
  #Original folder was '~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/1000_shuffled_phenos/'
  write.table(pheno,paste(paste0(dir,"pheno"),i,".txt",sep = "_"),row.names=F,col.names=F,quote=F)
}

----- /R code -----

## Calculate SNP heritability of the antagonism index by calculating REML estimate for true phenotypes
## Obtain P-value by comparing this value to REML estimates for 1000 permuted phenotypes

## Obtain kinship matrix
../ldak5.mac --calc-kins-direct kinsm_no_outlier --bfile f3c.lhm.snp --weights sect/weights.short --power -0.25
## REML, true
../ldak5.mac --reml all --grm kinsm_no_outlier --pheno pheno.txt --mpheno 6 
## REML, permuted
for i in *.txt; do ~/Documents/data/GWAS_data/gwas/ldak5.mac --reml ~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/reml_all/permutations/ant/$i --pheno $i --grm ~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/kinships_weighted/kinsm_no_outlier --mpheno 6; done
## Extracy SNP heritabilities of permuted phenotypes
for i in *.reml; do awk 'NR==15 {print $2}' $i > $i.her; done
## Concatenate SNP heritabilities of permuted phenotypes
cat *.her > all.her
rm *.reml.her

----- R code -----

## Import reml, permuted
all.ant <- read.table(paste0(dir,"all.her"))
names(all.ant) <- "Share"
all.ant$Share <- as.numeric(as.character(all.ant$Share))
## Empirical P-value
# Observed SNP heritability is 0.512216
sum(all.ant$Share>0.512216)/1000
#[1] 0.001

----- /R code -----

#############################
## ASSOCIATION ANALYSIS
#############################

## Mixed model of antagonistic axis, using weighted kinship matrix as random effect
../ldak5.mac --linear mm --pheno pheno.txt --bfile f3c.lhm.snp --grm kinships_weighted/kinsm_no_outlier --mpheno 6

#Mixed model, no correction for pop stratification (for QQ-plot, later)
../ldak5.mac --linear mm.no.correction --pheno pheno.txt --bfile f3c.lhm.snp --mpheno 6

----- R code -----

## Process genome-wide association data
## Import association P-values
## Mixed model, using weighted kinship matrix as covariate
assoc <- read.table(paste0(dir,"mm.assoc"),head=T)
assoc$Chromosome <- as.factor(assoc$Chromosome)
## Plink -> non-plink chromosome format
levels(assoc$Chromosome) <- c("2L","2R","3L","3R","X")
## Benjamini-Hochberg FDR correction
assoc$fdr <- p.adjust(assoc$Wald_P,"BH")

## Manhattan plot
assoc$Chromosome_numeric <- assoc$Chromosome
levels(assoc$Chromosome_numeric) <- 1:5
assoc$Chromosome_numeric <- as.numeric(as.character(assoc$Chromosome_numeric))
manhattan(assoc,chr="Chromosome_numeric",bp="Basepair",snp="Predictor",p="Wald_P",chrlabs=c("2L","2R","3L","3R","X"),cex = 0.4,col = c("blue4", "orange3"),suggestiveline = F,genomewideline = min(-log10(assoc$Wald_P)[assoc$fdr<0.3]),cex.lab=2,cex.axis=2,mar=c(5,5,5,5),ylim=c(0,7.2))


#############################
## QQ PLOTS
#############################

## QQ-plot
ord <- order(assoc[,7])
obsP <- assoc[ord,7]
N <- nrow(assoc)
expP <- 1:N/(N+1)
par(mar=c(5,5,5,5)+.1)
plot(-log10(expP),-log10(obsP),pch=19,xlab=expression(paste("Expected -log"["10"], "(P)")),ylab=expression(paste("Observed -log"["10"], "(P)")),cex=0.3,cex.main=1.5,cex.lab=1.2,cex.axis=1.2,col=rgb(0.5,0,1,0.5),las=1)
abline(a=0,b=1,col=2,lwd=2,lty=3)
## Genomic inflation factor
estlambda(assoc$Wald_P,method="median")

## QQ-plot, with no correction for relatedness
assoc.no.correction <- read.table(paste0(dir,"mm.no.correction.assoc"),head=T)
ord <- order(assoc.no.correction[,7])
obsP <- assoc.no.correction[ord,7]
N <- nrow(assoc.no.correction)
expP <- 1:N/(N+1)
points(-log10(expP),-log10(obsP),pch=19,xlab=expression(paste("Expected -log"["10"], "(P)")),ylab=expression(paste("Observed -log"["10"], "(P)")),cex=0.3,cex.main=1.5,cex.lab=1.2,cex.axis=1.2,col="black")
## Genomic inflation factor
estlambda(assoc.no.correction$Wald_P,method="median")

##########################################
## Permutation analysis
##########################################

## Richard's code; for running permutations when individuals are unequally related

estimate.mixed.model <- function( y, kinship, make.positive=TRUE ) {
  y = y[!is.na(y)]
  if ( length(y) < 1 ) return(NULL)
  
  use.ids = intersect( names(y), colnames(kinship))
  match.kinship = match( use.ids, colnames(kinship), nomatch=0)
  K = kinship[match.kinship,match.kinship]
  K.eigen.trunc = K.eigen = eigen(K,symmetric=TRUE)
  if ( make.positive ) {
    w.eigen = which( K.eigen$values/K.eigen$values[1] > 1.0e-8 )
    neigen = length(w.eigen) # number of non-trivial principal components
    K.eigen.trunc = K.eigen
    K.eigen.trunc$values = K.eigen.trunc$values[w.eigen]
    K.eigen.trunc$vectors = K.eigen.trunc$vectors[,w.eigen]
  }
  match.phen = match( use.ids, names(y), nomatch=0)
  y = y[match.phen]
  y = scale(y)
  
  z = t(K.eigen.trunc$vectors) %*% y # transformed phenotype
  zz = z*z
  lambda = K.eigen.trunc$values
  cat("estimating heritability\n")
  
  opt.theta1 = optim( c( 0.1 ),
                      fn =function(theta, zz, lambda ) { # log likelihood for mvn 
                        u = theta[1]*lambda+1-theta[1]
                        u = ifelse ( abs(u)<1.0e-10, 1.0e-10 , u ) 
                        return(sum(zz/u) + sum( log(u)))
                      },
                      gr=function( theta, zz, lambda){ # gradient of log L in terms of genetic and environmental variance
                        u = theta[1]*lambda+1-theta[1]
                        u = ifelse ( abs(u)<1.0e-10 ,1.0e-10, u ) 
                        v = (lambda-1)/u
                        g1 = sum( (1-zz/u)*v  )
                        return(c(g1))
                      },
                      zz, lambda, 
                      method="L-BFGS-B", lower = c( 1.0e-6), upper = c( 1.0 ), hessian=TRUE )
  
  vg = opt.theta1$par[1]
  ve = 1-vg
  E = K.eigen.trunc$vectors
  Lam = vg*K.eigen.trunc$values +ve
  V = Lam^(-0.5)    
  inv.sqrt.sigma = ( E %*% diag(V) ) %*% t(E)
  
  mixed.model.data = list( y=y, K=K, vg=vg, ve=ve, inv.sqrt.sigma=inv.sqrt.sigma, eigen=K.eigen.trunc )
  return(mixed.model.data)
}

mixed.model.residuals <- function( y, kinship, genotypes, nperm=nperm ) {
  mmd = estimate.mixed.model( y, kinship )
  
  use.ids = rownames(mmd$y)
  genos = genotypes[match( use.ids, rownames(genotypes), nomatch=0),]
  
  if ( nrow(genos) != length(use.ids)) {
    cat( "ERROR sample ids in genotypes do not match phenotypes\n")
    return(NULL);
  }
  
  genos = apply( genos, 2, function( g ) {
    s = sd(g, na.rm=TRUE)
    mu = mean(g, na.rm=TRUE)
    if ( s > 0 ) {
      g = ifelse ( is.na(g), 0.0, (g-mu)/s )
    } else {
      g = rep(0, length(g));
    }
    return(g)
  })
  
  mm.transformation = mmd$inv.sqrt.sigma    
  mm.transformed.y = mm.transformation %*% mmd$y
  mm.transformed.g = mm.transformation %*% genos
  
  mm.gwas.cor =  cor( mm.transformed.y, mm.transformed.g )
  n = length(mm.transformed.y)
  df = n-2
  t.stat = mm.gwas.cor*sqrt((df-2)/(1.0e-10+sqrt(1-mm.gwas.cor*mm.gwas.cor)))
  pval = 2*pt( abs(t.stat), df, low=FALSE )
  
  if ( nperm > 0 ) {
    perms = matrix( NA, ncol=nperm, nrow=n)
    for( i in 1:nperm ) {
      perms[,i] = sample(mm.transformed.y,replace=FALSE)
    }
    
    mm.gwas.cor.perm = cor( perms, mm.transformed.g )
    t.stat.perm = mm.gwas.cor.perm*sqrt((df-2)/(1.0e-10+sqrt(1-mm.gwas.cor.perm*mm.gwas.cor.perm)))
    pval.perm = 2*pt( abs(t.stat.perm), df, low=FALSE)
    pval.perm.empirical = sapply( 1:ncol(pval.perm), function( i, pval.perm, pval ) { mean(pval[i] > pval.perm[,i]) }, pval.perm, pval ) 
    results = list( pval=pval, pval.perm=pval.perm, pval.perm.empirical=pval.perm.empirical )
  } else {
    results = list( pval=pval)
  }
  
  return(results)
}

## Note that 'pheno_with_good_geno_info_no_outlier_ant.txt' (below) is a phenotype file where individuals with poor genotype information have been excluded, and where superfluous columns (i.e. those that do not correspond to antagonism index) have been removed

#original folders for load.data() were
#grm="~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/kinships_weighted" 
#pheno="~/Documents/data/GWAS_data/gwas/gemma" 
#geno="~/Documents/data/GWAS_data/gwas/callrate95_no_outlier"

load.data <- function( grm=paste0(dir,"kinsm_no_outlier.grm.raw"), pheno=paste0(dir,"pheno_with_good_geno_info_no_outlier_ant.txt"), geno=paste0(dir,"f3c.lhm.snp.ped"), save.file="genetic.RData") {
  
  print("starting load.data()")
  #Read phenotypes 
  p = read.table(pheno,  header=FALSE)
  #Y vector is vector of phenotype values
  y = p[,3]
  #names of Y vector are names of individuals
  names(y) = p[,2]
  
  #Read genotypes (Richard's version)
  #g = read.delim(geno, sep="\t", header=FALSE)
  #Matrix of genotypic values
  #gg = as.matrix(g[,7:ncol(g)])
  #Make missing values NA
  #gg = ifelse( gg=="0 0", NA, gg )
  #Rowames are names of individuals
  #rownames(gg) = g[,2]
  #print(dim(gg))
  
  #Read genotypes (Filip's version)
  g = fread(geno, sep="\t", header=FALSE)
  #Matrix of genotypic values
  gg = as.matrix(g[,7:ncol(g)])
  #Make missing values NA
  gg = ifelse( gg=="0 0", NA, gg )
  #Rowames are names of individuals
  rownames(gg) = g$V2
  print(dim(gg))
  
  #Apply geno function to genotypes
  #Makes AA TT format of ped file into 1 0 format
  dosages = apply(gg, 2, function( genos ) {
    genos = as.factor(genos)
    lev = sort(levels(genos))
    return(as.numeric(genos)-1)
  } )
  rownames(dosages) = names(y)
  
  #Read relationship matrix
  grm = read.table( grm, header=FALSE )
  K = as.matrix(grm)
  #Make names of individuals the rows and columns of the matrix
  rownames(K) = names(y)
  colnames(K) = names(y)
  #Write file which contains y (vector of phenotypes), dosages (genotype dosages), K (genetic relationship matrix)  
  save( y, dosages, K, file=save.file)
  print("ending load.data()")
}

make.plots <- function(data.file="genetic.RData", nperm=1000) {
  print("starting make.plots()")
  load.data()
  load(data.file)
  print("starting mixed.model.residuals()")
  results = mixed.model.residuals( y, K, dosages, nperm=nperm)
  print("ending mixed.model.residuals()")
  print("ending make.plots()")
  #original folder was '~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/'
  write.table(results$pval.perm.empirical,paste(paste0(dir,"Empirical_p_1k"),i,sep="_"),quote=F,col.names=F,row.names=F)
  print(i)
}


#Run 100,000 permutations
set.seed(123)
for (i in 1:100){
  make.plots()
}


## Import 100,000 permuted P values (each 1k set of permutations has been pasted in UNIX to make 'Empirical_p_all' file)
empirical_p_filip <- read.table(paste0(dir,"Empirical_p_all"))
empirical_p_filip$all <- rowSums(empirical_p_filip[,1:100])*1000
## Get Empirical P-value across 100,000 permutations
empirical_p_filip$Pval <- (empirical_p_filip$all+1)/100001
## Get Q-value across 100,000 permutations
empirical_p_filip$fdr <- p.adjust(empirical_p_filip$Pval,"BH")

## Make new columns in assoc dataframe
assoc$Empirical_p_100k <- empirical_p_filip$Pval
assoc$fdr.Empirical_p_100k <- empirical_p_filip$fdr

## Pearson's correlation between para and empirical candidates
cor.test(assoc$Empirical_p_100k,assoc$Wald_P)
## Regression slope
summary(lm(data=assoc,Empirical_p_100k~Wald_P))

## Plot empirical vs parametric P values
ggplot(assoc,aes(Wald_P,Empirical_p_100k))+
  geom_point(size=0.5)+
  theme_bw()+
  geom_smooth(method="lm",col="lightpink",fill="gray75")+
  xlab("Wald P")+
  ylab("Empirical P")+
  theme(legend.title=element_blank(),axis.text = element_text(size=25),axis.title = element_text(size=25),legend.text = element_text(size=25),legend.key.height=unit(3,"line"),legend.key.width=unit(3,"line"),legend.position="none",legend.background =element_blank())

## Overlap between parametric and empirical 'candidates' (minimum 2,372 empirical P-values)
assoc$Cand_parametric <- ifelse(assoc$fdr<0.3,1,0)
assoc$Cand_empirical <- ifelse(assoc$Empirical_p_100k<sort(assoc$Empirical_p_100k)[2372],1,0)
## Overlap table
table(subset(assoc,fdr<0.3 | assoc$Empirical_p_100k<sort(assoc$Empirical_p_100k)[2372])$Cand_empirical,subset(assoc,fdr<0.3 | assoc$Empirical_p_100k<sort(assoc$Empirical_p_100k)[2372])$Cand_parametric)
chisq.test(table(assoc$Cand_empirical,assoc$Cand_parametric))$expected

## Mean Q value for parametric candidates, estimated using parametric and empirical approaches
mean(assoc$fdr[assoc$Cand_parametric==1])
#[1] 0.27149
mean(assoc$fdr.Empirical_p_100k[assoc$Cand_parametric==1])
#[1] 0.407448

########################################
## Number of independent clumps
########################################

names(assoc)[2] <- "SNP"
#write.table(assoc,paste0(dir,"mm.assoc2"),quote=F,row.names=F)

----- /R code -----

plink --noweb --bfile f3c.lhm.snp --clump assoc_mixed_model/mm.assoc2 --clump-p1 0.00092903 --clump-p2 0.1 --clump-kb 10 --clump-r2 0.4 --clump-field Wald_P --out clumped_highly_associated_r0.4_10kb

----- R code -----

clumps <- read.table(paste0(dir,"clumped_highly_associated_r0.4_10kb.clumped"),head=T)
nrow(clumps)
#226

----- /R code -----

########################################
## Antagonistic vs. concordant
########################################

----- R code -----

## Phenotypic plot
pheno <- read.table(paste0(dir,"pheno.txt"),head=T)
ggplot(pheno,aes(Fit_mean_female,Fit_mean_male,col=Fit_mean_conc))+
  geom_hline(yintercept = 0,linetype="dashed",col="black")+
  geom_vline(xintercept = 0,linetype="dashed",col="black")+
  geom_point(size=4.5)+
  scale_size_continuous(range = c(1,6))+
  xlab("Relative female fitness")+
  ylab("Relative male fitness")+
  theme_bw()+
  theme(axis.title = element_text(size=25),axis.text = element_text(size=25),legend.position = "none")+
  xlim(c(-1.51,1.95))+
  ylim(c(-1.51,1.95))+
  scale_colour_gradientn(colours = c("steelblue1","red"),values=c(1,0))
  
----- /R code -----

## Association mixed model of concordant index, using weighted kinship matrix
../ldak5.mac --linear conc --pheno pheno.txt --bfile f3c.lhm.snp --grm kinships_weighted/kinsm_no_outlier --mpheno 5
mv conc.* assoc_mixed_model

----- R code -----

## Import concordant GWAS
cassoc <- read.table(paste0(dir,"conc.assoc"),head=T)
cassoc$Chromosome <- as.factor(cassoc$Chromosome)
levels(cassoc$Chromosome) <- c("2L","2R","3L","3R","X")
cassoc$fdr <- p.adjust(cassoc$Wald_P,"BH")

## P-value antagonistic vs. concordant histogram 
assoc$Wald_P_concordant <- cassoc$Wald_P
assoc$fdr_concordant <- cassoc$fdr
hist(assoc$Wald_P,breaks=200,ylim=c(0,8000),col=rgb(0,0,1,0.5),main="",xlab="P-value",cex.lab=1.8,cex.axis=1.8)
hist(assoc$Wald_P_concordant,breaks=200,ylim=c(0,8000),col=rgb(1,0.5,0,0.5),add=T)
legend(0.45,8000,legend=c("Concordant index","Antagonism index"),fill=c(rgb(1,0.5,0,0.5),rgb(0,0,1,0.5)),cex=1.2,box.lty = 0,bty="n")

## Q-value antagonistic vs. concordant histogram 
hist(assoc$fdr,breaks=200,ylim=c(0,40000),col=rgb(0,0,1,0.5),main="",xlab="Q-value",cex.lab=1.8,xaxt="n",cex.axis=1.8)
hist(assoc$fdr_concordant,breaks=50,ylim=c(0,40000),col=rgb(1,0.5,0,0.5),add=T)
legend(0.45,40000,legend=c("Concordant index","Antagonism index"),fill=c(rgb(1,0.5,0,0.5),rgb(0,0,1,0.5)),cex=1.2,box.lty = 0,bty="n")
axis(1,at=c(0,0.3,0.4,0.6,0.8,1),cex.axis=1.8)
abline(v=0.3,lwd=2,lty=3)

----- /R code -----

################################################
####Distributions of SNPs and candidate SNPs####
################################################

##Install Libraries
install.packages("ggplot2")
install.packages("dplyr")
install.packages("plyr")
install.packages("reshape")
install.packages("magrittr")
install.packages("gridExtra")
install.packages("grid")

##Load Libraries
library(ggplot2)
library(dplyr)
library(plyr)
library(reshape)
library(magrittr)
library(gridExtra)
library(grid)

##General theme for plots
theme_main <- function() {
  theme_bw() +
    theme(
      #panel.grid.major = element_blank(),
      #panel.grid.minor = element_blank(),
      axis.text = element_text(size = 25),
      axis.title = element_text(size = 30),
      strip.text = element_text(size = 30),
      legend.text= element_text(size = 25),
      legend.title = element_text(size = 30),
      plot.title = element_text(size = 40, face = "bold")
    )
}

####Read SNP dataset
GWAS_SNP <-  read.table("Full_SNP_FILE", header = T)

##Recode non-antagonistic SNPs to 0
GWAS_SNP$Candidate[is.na(GWAS_SNP$Candidate)] <- 0


####Test whether candidate SNPs are significantly clustered along chromosome arms, split X and autosomes
####Calculate median distances between SNPs for Autosomes and X chromsome
###get observed distances and put in order
c2l_cs <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "2L" & GWAS_SNP$Candidate == 1) %>% .[order(.$Basepair),]
c2r_cs <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "2R" & GWAS_SNP$Candidate == 1) %>% .[order(.$Basepair),]
c3l_cs <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "3L" & GWAS_SNP$Candidate == 1) %>% .[order(.$Basepair),]
c3r_cs <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "3R" & GWAS_SNP$Candidate == 1) %>% .[order(.$Basepair),]
cx_cs <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "X" & GWAS_SNP$Candidate == 1) %>% .[order(.$Basepair),]

c2l_cs$Distance <- 0
c2l_cs$Distance[-1] <- c2l_cs$Basepair[-1] - c2l_cs$Basepair[-length(c2l_cs$Basepair)];

c2r_cs$Distance <- 0
c2r_cs$Distance[-1] <- c2r_cs$Basepair[-1] - c2r_cs$Basepair[-length(c2r_cs$Basepair)];

c3l_cs$Distance <- 0
c3l_cs$Distance[-1] <- c3l_cs$Basepair[-1] - c3l_cs$Basepair[-length(c3l_cs$Basepair)];

c3r_cs$Distance <- 0
c3r_cs$Distance[-1] <- c3r_cs$Basepair[-1] - c3r_cs$Basepair[-length(c3r_cs$Basepair)];

cx_cs$Distance <- 0
cx_cs$Distance[-1] <- cx_cs$Basepair[-1] - cx_cs$Basepair[-length(cx_cs$Basepair)];

fulldist_cs <- rbind(c2l_cs, c2r_cs, c3l_cs, c3r_cs, cx_cs)

median(fulldist_cs$Distance[fulldist_cs$Chrom !="X"]) #auto median dist = 147

median(fulldist_cs$Distance[fulldist_cs$Chrom =="X"]) #X median dist = 298

####Perfrom resampling test
##First calculate median distances across all SNPs
c2l <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "2L") %>% .[order(.$Basepair),]
c2r <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "2R") %>% .[order(.$Basepair),]
c3l <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "3L") %>% .[order(.$Basepair),]
c3r <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "3R") %>% .[order(.$Basepair),]
cx <- subset(GWAS_SNP, GWAS_SNP$Chromosome == "X") %>% .[order(.$Basepair),]

c2l$Distance <- 0
c2l$Distance[-1] <- c2l$Basepair[-1] - c2l$Basepair[-length(c2l$Basepair)];

c2r$Distance <- 0
c2r$Distance[-1] <- c2r$Basepair[-1] - c2r$Basepair[-length(c2r$Basepair)];

c3l$Distance <- 0
c3l$Distance[-1] <- c3l$Basepair[-1] - c3l$Basepair[-length(c3l$Basepair)];

c3r$Distance <- 0
c3r$Distance[-1] <- c3r$Basepair[-1] - c3r$Basepair[-length(c3r$Basepair)];

cx$Distance <- 0
cx$Distance[-1] <- cx$Basepair[-1] - cx$Basepair[-length(cx$Basepair)];

fulldist <- rbind(c2l, c2r, c3l, c3r, cx)

####Resampling test
##create a matrix for the results, one column for autosomes, one for the X
resamp_median_dist <- matrix(ncol = 2, nrow = 1000)

##loop through replicate resamples
for(i in 1:1000){
  ## create a zero-length vector for autosomal distances
  tmp_dists_auto <- vector(mode = "numeric", length = 0)
  
  ## cycle through chromosomes
  for(j in 1:length(c("2L", "2R", "3L", "3R"))){
    
    ## sample random positions from that chromosome, getting the same number as that of significant SNPs
    tmp_positions <- sample(x = fulldist$Basepair[fulldist$Chromosome == c("2L", "2R", "3L", "3R")[j]], size = sum(1 * fulldist$Candidate[fulldist$Chromosome==c("2L", "2R", "3L", "3R")[j]]))
    
    ## put positions in increasing order
    tmp_positions <- tmp_positions[order(tmp_positions)]
    
    ## calculate distances from positions and append to autosomal distance vector
    tmp_dists_auto <- c(tmp_dists_auto, tmp_positions[-1] - tmp_positions[-length(tmp_positions)])}
  
  ## sample random positions for the X chromosome (note: this recycles the variable tmp_positions)
  tmp_positions <- sample(x = fulldist$Basepair[fulldist$Chromosome == "X"], size = sum(1 * fulldist$Candidate[fulldist$Chromosome == "X"]))
  
  ## put in order
  tmp_positions <- tmp_positions[order(tmp_positions)]
  
  ## calculate distances for the X
  tmp_dists_X <- tmp_positions[-1] - tmp_positions[-length(tmp_positions)]
  
  ## calculate median distances and store in the corresponding row of the results matrix
  resamp_median_dist[i,] <- c(median(tmp_dists_auto), median(tmp_dists_X))
}

##Tidy names
resamp_median_dist <- as.data.frame(resamp_median_dist)
names(resamp_median_dist) <- c("Autosomes", "X-Chromosome")

##save output data
write.table(resamp_median_dist, file = "S5_Data.txt", quote = F, row.names = F)

####Plot results of resampling test - FigS5
##Use Fig S5 datafile
resamp_median_dist <- read.table("S5_Data.txt", header = T)
##restructure data for plotting
resamp_median_dist_reform <- melt(resamp_median_dist)

##Set observed median for autosomes and X
vline_data <- data.frame(variable = levels(resamp_median_dist_reform$variable), vline = c(median(fulldist_cs$Distance[fulldist_cs$Chrom != "X"]), median(fulldist_cs$Distance[fulldist_cs$Chrom == "X"])))

##Plot - use FigS5 datafile
resampled_distance_plot <-
  ggplot(resamp_median_dist_reform, aes(x= value)) +
  facet_wrap(~ variable, ncol = 1, scales = "free_y") +
  geom_density(fill = "lightblue") +
  theme_main() +
  geom_vline(data = vline_data, aes(xintercept = vline), linetype = "dashed", colour = "red") +
  xlab("Median distance between resampled sites") +
  ylab("Density")
