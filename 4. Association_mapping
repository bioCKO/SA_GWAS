library(data.table)
library(ggplot2)
library(GenABEL)
library(qqman)
library(viridis)
library(scales)
library(qvalue)

#############################
## ASSOCIATION ANALYSIS
#############################

## Cut genome into sections (default settings)
./ldak5.mac --cut-weights sect --bfile f3c.lhm.snp
## Calculate LDAK SNP weightings
./ldak5.mac --calc-weights-all sect --bfile f3c.lhm.snp
## Estimate kinship matrix using by applying SNP weightings and defining MAF-effect size relationsip (LDAK recommended value=0.25)
./ldak5.mac --calc-kins-direct kinsm_no_outlier --bfile f3c.lhm.snp --weights sect/weights.all --power -.25 --kinship-raw YES
## Extract first 5 principal components
../ldak5.mac --pca kinsm_no_outlier --grm kinsm_no_outlier
## Extract Principal component loadings
./ldak5.mac --calc-pca-loads kinsm_no_outlier --grm kinsm_no_outlier --bfile f3c.lhm.snp --pcastem kinsm_no_outlier

## Mixed model of antagonistic axis, using weighted kinship matrix as random effect
../ldak5.mac --linear mm --pheno pheno.txt --bfile f3c.lhm.snp --grm kinships_weighted/kinsm_no_outlier --mpheno 6

## Mixed model, no correction for pop stratification (used for QQ-plot comparison, later)
../ldak5.mac --linear mm.no.correction --pheno pheno.txt --bfile f3c.lhm.snp --mpheno 6


## Process genome-wide association data

----- R code -----
## Manhattan plot
#Mixed model, using weighted kinship matrix as covariate
assoc <- read.table("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/assoc_mixed_model/mm.assoc",head=T)
assoc$Chromosome <- as.factor(assoc$Chromosome)
levels(assoc$Chromosome) <- c("2L","2R","3L","3R","X")
assoc$fdr <- p.adjust(assoc$Wald_P,"BH")
levels(assoc$Chromosome) <- 1:5
assoc$Chromosome <- as.numeric(as.character(assoc$Chromosome))
manhattan(assoc,chr="Chromosome",bp="Basepair",snp="Predictor",p="Wald_P",chrlabs=c("2L","2R","3L","3R","X"),cex = 0.4,col = c("blue4", "orange3"),genomewideline = -log10(0.05/nrow(assoc)),suggestiveline = min(-log10(assoc$Wald_P)[assoc$fdr<0.3]),cex.lab=2,cex.axis=2,mar=c(5,5,5,5),ylim=c(0,7.2))

## Histogram of P-values
par(mfrow=c(1,2))
hist(assoc$Wald_P,breaks=100)
hist(assoc$fdr,breaks=100)
p1 <- ggplot(assoc,aes(Wald_P))+geom_histogram(bins = 100)+xlab("P values")+theme_grey()+theme(axis.title = element_text(size=30),axis.text = element_text(size=15))
p2 <- ggplot(assoc,aes(fdr))+geom_histogram(bins = 100)+xlab("False Discovery Rate")+theme_grey()+theme(axis.title = element_text(size=30),axis.text = element_text(size=15))+xlim(c(0,1.05))
grid.arrange(p1,p2)

## QQ-plot
ord <- order(assoc[,7])
obsP <- assoc[ord,7]
N <- nrow(assoc)
expP <- 1:N/(N+1)
par(mar=c(5,5,5,5)+.1)
plot(-log10(expP),-log10(obsP),pch=19,xlab=expression(paste("Expected -log"["10"], "(P)")),ylab=expression(paste("Observed -log"["10"], "(P)")),cex=0.3,cex.main=1.5,cex.lab=1.2,cex.axis=1.2,col=rgb(0.5,0,1,0.5),las=1)
abline(a=0,b=1,col=2,lwd=2,lty=3)
#genomic inflation factor
estlambda(assoc$Wald_P,method="median")

## QQ-plot, with no correction for relatedness
assoc.no.correction <- read.table("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/assoc_mixed_model/mm.no.correction.assoc",head=T)
ord <- order(assoc.no.correction[,7])
obsP <- assoc.no.correction[ord,7]
N <- nrow(assoc.no.correction)
expP <- 1:N/(N+1)
points(-log10(expP),-log10(obsP),pch=19,xlab=expression(paste("Expected -log"["10"], "(P)")),ylab=expression(paste("Observed -log"["10"], "(P)")),cex=0.3,cex.main=1.5,cex.lab=1.2,cex.axis=1.2,col="black")
abline(a=0,b=1,col=2,lwd=2,lty=3)
estlambda(assoc.no.correction$Wald_P,method="median")
----- R code -----


##########################################
## Permutation analysis
##########################################

----- R code -----
estimate.mixed.model <- function( y, kinship, make.positive=TRUE ) {
  y = y[!is.na(y)]
  if ( length(y) < 1 ) return(NULL)
  
  use.ids = intersect( names(y), colnames(kinship))
  match.kinship = match( use.ids, colnames(kinship), nomatch=0)
  K = kinship[match.kinship,match.kinship]
  K.eigen.trunc = K.eigen = eigen(K,symmetric=TRUE)
  if ( make.positive ) {
    w.eigen = which( K.eigen$values/K.eigen$values[1] > 1.0e-8 )
    neigen = length(w.eigen) # number of non-trivial principal components
    K.eigen.trunc = K.eigen
    K.eigen.trunc$values = K.eigen.trunc$values[w.eigen]
    K.eigen.trunc$vectors = K.eigen.trunc$vectors[,w.eigen]
  }
  match.phen = match( use.ids, names(y), nomatch=0)
  y = y[match.phen]
  y = scale(y)
  
  z = t(K.eigen.trunc$vectors) %*% y # transformed phenotype
  zz = z*z
  lambda = K.eigen.trunc$values
  cat("estimating heritability\n")
  
  opt.theta1 = optim( c( 0.1 ),
                      fn =function(theta, zz, lambda ) { # log likelihood for mvn 
                        u = theta[1]*lambda+1-theta[1]
                        u = ifelse ( abs(u)<1.0e-10, 1.0e-10 , u ) 
                        return(sum(zz/u) + sum( log(u)))
                      },
                      gr=function( theta, zz, lambda){ # gradient of log L in terms of genetic and environmental variance
                        u = theta[1]*lambda+1-theta[1]
                        u = ifelse ( abs(u)<1.0e-10 ,1.0e-10, u ) 
                        v = (lambda-1)/u
                        g1 = sum( (1-zz/u)*v  )
                        return(c(g1))
                      },
                      zz, lambda, 
                      method="L-BFGS-B", lower = c( 1.0e-6), upper = c( 1.0 ), hessian=TRUE )
  
  vg = opt.theta1$par[1]
  ve = 1-vg
  E = K.eigen.trunc$vectors
  Lam = vg*K.eigen.trunc$values +ve
  V = Lam^(-0.5)    
  inv.sqrt.sigma = ( E %*% diag(V) ) %*% t(E)
  
  mixed.model.data = list( y=y, K=K, vg=vg, ve=ve, inv.sqrt.sigma=inv.sqrt.sigma, eigen=K.eigen.trunc )
  return(mixed.model.data)
}

mixed.model.residuals <- function( y, kinship, genotypes, nperm=nperm ) {
  mmd = estimate.mixed.model( y, kinship )
  
  use.ids = rownames(mmd$y)
  genos = genotypes[match( use.ids, rownames(genotypes), nomatch=0),]
  
  if ( nrow(genos) != length(use.ids)) {
    cat( "ERROR sample ids in genotypes do not match phenotypes\n")
    return(NULL);
  }
  
  genos = apply( genos, 2, function( g ) {
    s = sd(g, na.rm=TRUE)
    mu = mean(g, na.rm=TRUE)
    if ( s > 0 ) {
      g = ifelse ( is.na(g), 0.0, (g-mu)/s )
    } else {
      g = rep(0, length(g));
    }
    return(g)
  })
  
  mm.transformation = mmd$inv.sqrt.sigma    
  mm.transformed.y = mm.transformation %*% mmd$y
  mm.transformed.g = mm.transformation %*% genos
  
  mm.gwas.cor =  cor( mm.transformed.y, mm.transformed.g )
  n = length(mm.transformed.y)
  df = n-2
  t.stat = mm.gwas.cor*sqrt((df-2)/(1.0e-10+sqrt(1-mm.gwas.cor*mm.gwas.cor)))
  pval = 2*pt( abs(t.stat), df, low=FALSE )
  
  if ( nperm > 0 ) {
    perms = matrix( NA, ncol=nperm, nrow=n)
    for( i in 1:nperm ) {
      perms[,i] = sample(mm.transformed.y,replace=FALSE)
    }
    
    mm.gwas.cor.perm = cor( perms, mm.transformed.g )
    t.stat.perm = mm.gwas.cor.perm*sqrt((df-2)/(1.0e-10+sqrt(1-mm.gwas.cor.perm*mm.gwas.cor.perm)))
    pval.perm = 2*pt( abs(t.stat.perm), df, low=FALSE)
    pval.perm.empirical = sapply( 1:ncol(pval.perm), function( i, pval.perm, pval ) { mean(pval[i] > pval.perm[,i]) }, pval.perm, pval ) 
    results = list( pval=pval, pval.perm=pval.perm, pval.perm.empirical=pval.perm.empirical )
  } else {
    results = list( pval=pval)
  }
  
  return(results)
}

load.data <- function( grm="~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/kinships_weighted/kinsm_no_outlier.grm.raw", pheno="~/Documents/data/GWAS_data/gwas/gemma/pheno_with_good_geno_info_no_outlier_ant.txt", geno="~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/f3c.lhm.snp.ped", save.file="genetic.RData") {
  
  print("starting load.data()")
  #Read phenotypes 
  p = read.table(pheno,  header=FALSE)
  #Y vector is vector of phenotype values
  y = p[,3]
  #names of Y vector are names of individuals
  names(y) = p[,2]
  
  #Read genotypes (Richard's version)
  #g = read.delim(geno, sep="\t", header=FALSE)
  #Matrix of genotypic values
  #gg = as.matrix(g[,7:ncol(g)])
  #Make missing values NA
  #gg = ifelse( gg=="0 0", NA, gg )
  #Rowames are names of individuals
  #rownames(gg) = g[,2]
  #print(dim(gg))
  
  #Read genotypes (Filip's version)
  g = fread(geno, sep="\t", header=FALSE)
  #Matrix of genotypic values
  gg = as.matrix(g[,7:ncol(g)])
  #Make missing values NA
  gg = ifelse( gg=="0 0", NA, gg )
  #Rowames are names of individuals
  rownames(gg) = g$V2
  print(dim(gg))
  
  #Apply geno function to genotypes
  #Makes AA TT format of ped file into 1 0 format
  dosages = apply(gg, 2, function( genos ) {
    genos = as.factor(genos)
    lev = sort(levels(genos))
    return(as.numeric(genos)-1)
  } )
  rownames(dosages) = names(y)
  
  #Read relationship matrix
  grm = read.table( grm, header=FALSE )
  K = as.matrix(grm)
  #Make names of individuals the rows and columns of the matrix
  rownames(K) = names(y)
  colnames(K) = names(y)
  #Write file which contains y (vector of phenotypes), dosages (genotype dosages), K (genetic relationship matrix)  
  save( y, dosages, K, file=save.file)
  print("ending load.data()")
}

make.plots <- function(data.file="genetic.RData", nperm=1000) {
  print("starting make.plots()")
  load.data()
  load(data.file)
  print("starting mixed.model.residuals()")
  results = mixed.model.residuals( y, K, dosages, nperm=nperm)
  print("ending mixed.model.residuals()")
  print("ending make.plots()")
  write.table(results$pval.perm.empirical,paste("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_1k",i,sep="_"),quote=F,col.names=F,row.names=F)
  print(i)
}


#Run 100,000 permutations
set.seed(123)
for (i in 1:100){
  make.plots()
}


## Import my 100,000 permutations and Max's 400,000 permutations
empirical_p_filip <- read.table("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_all")
empirical_p_filip$all <- rowSums(empirical_p_filip[,1:100])*1000
empirical_p_filip$Pval <- (empirical_p_filip$all+1)/100001
empirical_p_filip$fdr <- qvalue(empirical_p_filip$Pval)$qvalues

#Max's permuted values
empirical_p_max1 <- read.csv("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_100_1_summary.csv")
empirical_p_max2 <- read.csv("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_100_2_summary.csv")
empirical_p_max3 <- read.csv("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_100_3_summary.csv")
empirical_p_max4 <- read.csv("~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/richard_analysis/Empirical_p_100_4_summary.csv")

#Combine Filip's and Max's permuted values
empirical_p_500k <- cbind(empirical_p_filip[,101],empirical_p_max1,empirical_p_max2,empirical_p_max3,empirical_p_max4)
empirical_p_500k$all <- rowSums(empirical_p_500k[,1:5])
empirical_p <- data.frame((empirical_p_500k$all+1)/(500000+1))
names(empirical_p) <- "Pval"
#FDR, Storey and Tibshirani's method
empirical_p$fdr <- qvalue(empirical_p$Pval)$qvalues

#Add empirical P values to assoc dataframe
assoc$Empirical_p_500k <- empirical_p$Pval
assoc$fdr.Empirical_p_500k <- empirical_p$fdr

#Corr between parametric and empirical P-values
cor.test(assoc$Empirical_p_500k,assoc$Wald_P)

#Slope of relationship between parametric and empirical P-values
summary(lm(data=assoc,Empirical_p_500k~Wald_P))

#Scatter plot
ggplot(assoc,aes(Wald_P,Empirical_p_500k))+
         geom_point(size=0.5)+
         theme_bw()+
         geom_smooth(method="lm",col="lightpink",fill="gray75")+
  xlab("Wald P")+
  ylab("Empirical P")+
  theme(legend.title=element_blank(),axis.text = element_text(size=25),axis.title = element_text(size=25),legend.text = element_text(size=25),legend.key.height=unit(3,"line"),legend.key.width=unit(3,"line"),legend.position="none",legend.background =element_blank())

#Histogram overlay
par(mfrow=c(1,1))
hist(assoc$Wald_P,breaks=200,ylim=c(0,8000),col=rgb(0,0,1,0.5),main="",xlab="P-value",cex.lab=1.8,cex.axis=1.8)
hist(assoc$Empirical_p,breaks=200,ylim=c(0,8000),col=rgb(0.5,0.9,0.2,0.6),add=T,cex.lab=1.8,cex.axis=1.8)
legend(0.45,8000,legend=c("Wald P-value","Empirical P-value"),fill=c(rgb(0,0,1,0.5),rgb(0.5,0.9,0.2,0.6)),cex=1.5,box.lty = 0,bty="n")

#QQplot
ord <- order(assoc[,"Empirical_p"])
obsP <- assoc[ord,"Empirical_p"]
N <- nrow(assoc)
expP <- 1:N/(N+1)
plot(-log10(expP),-log10(obsP),pch=19,xlab=expression(paste("Expected -log"["10"], "(P)")),ylab=expression(paste("Observed -log"["10"], "(P)")),cex=0.3,cex.main=1.5,cex.lab=1.2,cex.axis=1.2,col="lightpink",las=1)
abline(a=0,b=1,col=2,lwd=2,lty=3)
#genomic inflation factor
estlambda(assoc$Empirical_p,method="median")

write.table(assoc,"~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/assoc_mixed_model/mm.assoc4",quote=F,row.names=F)
----- R code -----

########################################
## Number of independent clumps
########################################

----- R code -----
names(assoc)[2] <- "SNP"
#write.table(assoc,"~/Documents/data/GWAS_data/gwas/callrate95_no_outlier/assoc_mixed_model/mm.assoc2",quote=F,row.names=F)
----- R code -----

plink --noweb --bfile f3c.lhm.snp --clump assoc_mixed_model/mm.assoc2 --clump-p1 0.00092903 --clump-p2 0.1 --clump-kb 10 --clump-r2 0.4 --clump-field Wald_P --out clumped_highly_associated_r0.4_10kb
